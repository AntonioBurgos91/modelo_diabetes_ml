{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0c761-5cef-417f-a828-0449cdccf2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar pandas para la manipulación de datos\n",
    "import pandas as pd\n",
    "\n",
    "# URL del conjunto de datos\n",
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "\n",
    "# Definir los nombres de las columnas, ya que el archivo CSV original no los incluye\n",
    "columnas = [\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\",\n",
    "            \"BMI\", \"DiabetesPedigreeFunction\", \"Age\", \"Outcome\"]\n",
    "\n",
    "# Cargar el dataset utilizando pandas\n",
    "df = pd.read_csv(url, names=columnas)\n",
    "\n",
    "# Mostrar las primeras 5 filas del dataset para una inspección inicial\n",
    "print(\"Primeras filas del DataFrame:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f432c5-2e5d-41ab-acc2-5466c808c6f6",
   "metadata": {},
   "source": [
    "### 1. Análisis Exploratorio de Datos (EDA) - Parte 1: Entendimiento Básico\n",
    "\n",
    "Una vez cargados los datos, el siguiente paso crucial es el Análisis Exploratorio de Datos (EDA). Esto nos permite entender la estructura, calidad y las principales características del conjunto de datos.\n",
    "\n",
    "Realizaremos las siguientes comprobaciones:\n",
    "1.  **Forma del dataset:** Para conocer el número de filas (observaciones) y columnas (características).\n",
    "2.  **Distribución de la variable objetivo (`Outcome`):** Es vital saber si las clases (diabetes sí/no) están balanceadas o no. Un desbalanceo puede afectar el rendimiento del modelo y requerir técnicas especiales.\n",
    "3.  **Estadísticas descriptivas:** Nos proporcionan un resumen numérico de cada característica (media, desviación estándar, mínimos, máximos, cuartiles), lo cual ayuda a identificar rangos de valores y posibles anomalías.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "El EDA revela la calidad de los datos y si son adecuados para el problema que queremos resolver. Por ejemplo, si la variable objetivo está muy desbalanceada (pocos casos de diabetes), el modelo podría tener dificultades para aprender a identificarlos. Conocer esto de antemano permite planificar estrategias para mitigar estos problemas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3bfb9-b609-4711-bc5a-5e1dc83e09da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener las dimensiones del dataset (filas, columnas)\n",
    "print(\"Forma del dataset (filas, columnas):\", df.shape)\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Analizar la distribución de la variable objetivo 'Outcome'\n",
    "# Outcome: 0 significa sin diabetes, 1 significa con diabetes\n",
    "print(\"Distribución de la variable objetivo 'Outcome':\")\n",
    "print(df[\"Outcome\"].value_counts())\n",
    "print(\"\\nPorcentaje de cada clase:\")\n",
    "print(df[\"Outcome\"].value_counts(normalize=True) * 100)\n",
    "print(\"\\n--------------------------------------------------\\n\")\n",
    "\n",
    "# Obtener estadísticas descriptivas para cada columna numérica\n",
    "print(\"Estadísticas descriptivas del dataset:\")\n",
    "df.describe().transpose() # Transpose para mejor visualización"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4759ffed-058e-4192-9b59-195d6187ad4d",
   "metadata": {},
   "source": [
    "**Interpretación de los resultados iniciales:**\n",
    "*   El dataset tiene 768 observaciones y 9 características (incluyendo la variable objetivo).\n",
    "*   La variable 'Outcome' muestra un desbalanceo: aproximadamente 65% de los casos son '0' (sin diabetes) y 35% son '1' (con diabetes). Esto es importante tenerlo en cuenta para la evaluación del modelo y posibles técnicas de remuestreo.\n",
    "*   Al observar las estadísticas descriptivas, notamos que algunas columnas como `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin` y `BMI` tienen valores mínimos de 0. Fisiológicamente, estos valores no pueden ser cero para una persona viva. Esto sugiere que los ceros en estas columnas podrían estar representando datos faltantes o erróneos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0165d47a-d12a-41ee-bb5f-5d9d7d57bd64",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento de Datos - Parte 1: Manejo de Valores Anómalos (Ceros)\n",
    "\n",
    "Como identificamos en el EDA, ciertas columnas tienen valores '0' que no son realistas. Procederemos a reemplazar estos ceros con `NaN` (Not a Number), que es la forma estándar de representar valores faltantes en pandas. Esto nos permitirá luego aplicar estrategias de imputación adecuadas.\n",
    "\n",
    "Las columnas a tratar son: `Glucose`, `BloodPressure`, `SkinThickness`, `Insulin`, `BMI`.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "La calidad de los datos de entrada impacta directamente la calidad del modelo predictivo. Ignorar valores anómalos o incorrectos puede llevar a un modelo que aprenda patrones erróneos y, por lo tanto, tome decisiones incorrectas. Corregir estos datos es un paso esencial hacia la fiabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9361df-15f7-418f-8b8e-2c9cc775e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar numpy para utilizar np.nan (Not a Number)\n",
    "import numpy as np\n",
    "\n",
    "# Lista de columnas donde el valor 0 es fisiológicamente implausible y probablemente indica un dato faltante\n",
    "columnas_con_ceros_implausibles = [\"Glucose\", \"BloodPressure\", \"SkinThickness\", \"Insulin\", \"BMI\"]\n",
    "\n",
    "# Reemplazar 0 con NaN en las columnas especificadas\n",
    "df[columnas_con_ceros_implausibles] = df[columnas_con_ceros_implausibles].replace(0, np.nan)\n",
    "\n",
    "# Verificar la cantidad de valores nulos (NaN) por columna después del reemplazo\n",
    "print(\"Cantidad de valores nulos por columna después de reemplazar ceros:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94844563-5111-45b3-a6a7-69f6f9dbf49c",
   "metadata": {},
   "source": [
    "**Observación:**\n",
    "Ahora vemos que las columnas `Insulin` y `SkinThickness` tienen una cantidad considerable de valores faltantes (casi la mitad y un tercio de los datos, respectivamente). `Glucose`, `BloodPressure` y `BMI` también tienen algunos valores faltantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad917769-1810-43fb-8ec0-07573c5665c9",
   "metadata": {},
   "source": [
    "### 2. Preprocesamiento de Datos - Parte 2: Imputación de Valores Faltantes\n",
    "\n",
    "Los valores faltantes deben ser manejados antes de entrenar un modelo de Machine Learning, ya que la mayoría de los algoritmos no los aceptan. Una estrategia común es la **imputación**, que consiste en reemplazar los `NaN` con un valor estadístico calculado a partir de los datos existentes en esa columna (e.g., la media o la mediana).\n",
    "\n",
    "Aquí, optaremos por imputar los valores faltantes con la **media** de cada columna respectiva. Es importante calcular esta media *solo* con los datos de entrenamiento en un escenario real para evitar fuga de datos (data leakage) del conjunto de prueba. Sin embargo, para simplificar esta etapa inicial y dado que aún no hemos dividido los datos, aplicaremos la media global. Más adelante, al construir pipelines más robustos, la imputación se realizará correctamente dentro de los folds de validación cruzada o después de la división entrenamiento/prueba.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "No podemos simplemente eliminar todas las filas con datos faltantes, especialmente si son muchas, ya que perderíamos información valiosa. La imputación nos permite conservar la mayor cantidad de datos posible, rellenando los vacíos de manera lógica para que el modelo pueda trabajar con un dataset completo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45112e98-3360-47a2-aff1-467de7e2697d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputar los valores NaN con la media de cada columna\n",
    "# Es importante notar que en un flujo de trabajo riguroso, esta media se calcularía SOLO en el conjunto de entrenamiento.\n",
    "# Por ahora, para mantener la simplicidad en esta etapa exploratoria, usamos la media del dataset completo.\n",
    "df[columnas_con_ceros_implausibles] = df[columnas_con_ceros_implausibles].fillna(df[columnas_con_ceros_implausibles].mean())\n",
    "\n",
    "# Verificar que no queden valores nulos\n",
    "print(\"Cantidad de valores nulos por columna después de la imputación:\")\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb90959-2477-464d-b068-89c50b8c587d",
   "metadata": {},
   "source": [
    "**Comentario:**\n",
    "Todos los valores nulos han sido imputados. Ahora nuestro dataset está numéricamente completo y listo para la siguiente fase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9803aa-f610-449c-a5c5-73921845e47d",
   "metadata": {},
   "source": [
    "### 3. Visualización de Datos (EDA - Parte 2)\n",
    "\n",
    "Ahora que los datos están limpios, podemos realizar algunas visualizaciones para entender mejor las distribuciones y relaciones entre las variables.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "Las visualizaciones traducen números complejos en gráficos comprensibles. Permiten identificar patrones, tendencias o anomalías de forma intuitiva, facilitando la comunicación de los hallazgos y la generación de hipótesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce96ced0-a2af-4dfb-b19e-2d74859cf237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Configuración general para los gráficos\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# 1. Distribución de la variable objetivo 'Outcome'\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.countplot(x='Outcome', data=df)\n",
    "plt.title('Distribución de la Variable Objetivo (Outcome)')\n",
    "plt.xlabel('Outcome (0: No Diabetes, 1: Diabetes)')\n",
    "plt.ylabel('Cantidad de Pacientes')\n",
    "plt.show()\n",
    "\n",
    "# 2. Histogramas de todas las características para ver sus distribuciones\n",
    "df.hist(figsize=(15,10), bins=20)\n",
    "plt.suptitle('Histogramas de Todas las Características', y=1.02, size=16)\n",
    "plt.tight_layout() # Ajusta automáticamente los subplots para que encajen\n",
    "plt.show()\n",
    "\n",
    "# 3. Matriz de Correlación\n",
    "# La correlación nos indica la relación lineal entre pares de variables.\n",
    "# Valores cercanos a 1 o -1 indican una fuerte correlación positiva o negativa, respectivamente.\n",
    "# Valores cercanos a 0 indican poca o ninguna correlación lineal.\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df.corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title('Matriz de Correlación de Características')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff328fc3-8956-4aee-82f4-ce79dc20f002",
   "metadata": {},
   "source": [
    "**Interpretación de las Visualizaciones:**\n",
    "*   **Distribución de Outcome:** Confirma visualmente el desbalanceo de clases que vimos antes.\n",
    "*   **Histogramas:** Nos muestran la forma de la distribución de cada variable. Por ejemplo, `Age` y `DiabetesPedigreeFunction` están sesgadas a la derecha. `Glucose` y `BMI` se asemejan más a una distribución normal.\n",
    "*   **Matriz de Correlación:**\n",
    "    *   `Glucose` tiene la correlación positiva más alta con `Outcome` (0.49), lo que sugiere que niveles más altos de glucosa están asociados con una mayor probabilidad de diabetes. Esto es médicamente esperado.\n",
    "    *   `BMI` (0.31) y `Age` (0.24) también muestran correlaciones positivas moderadas con `Outcome`.\n",
    "    *   `Pregnancies` y `Age` tienen una correlación positiva (0.54), lo cual es lógico.\n",
    "    *   Es importante notar que la correlación mide relaciones *lineales*. Puede haber relaciones no lineales importantes que no se capturen aquí."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a3f4a4-4273-4125-ab62-d3ef82982d11",
   "metadata": {},
   "source": [
    "### 4. Preparación de Datos para el Modelo: División en Conjuntos de Entrenamiento y Prueba\n",
    "\n",
    "Antes de entrenar cualquier modelo, es crucial dividir nuestro conjunto de datos en dos subconjuntos:\n",
    "1.  **Conjunto de Entrenamiento (Training set):** Se utiliza para que el modelo aprenda los patrones de los datos.\n",
    "2.  **Conjunto de Prueba (Test set):** Se utiliza para evaluar el rendimiento del modelo en datos que no ha visto antes. Esto nos da una medida más realista de cómo se comportará el modelo en el mundo real.\n",
    "\n",
    "Separaremos las características (variables predictoras, `X`) de la variable objetivo (lo que queremos predecir, `y`).\n",
    "\n",
    "Usaremos `train_test_split` de `sklearn.model_selection`.\n",
    "*   `test_size=0.2`: Reservamos el 20% de los datos para el conjunto de prueba.\n",
    "*   `random_state=42`: Asegura que la división sea la misma cada vez que ejecutamos el código, para reproducibilidad.\n",
    "*   `stratify=y`: Es muy importante cuando hay desbalanceo de clases. Asegura que la proporción de la variable objetivo (`Outcome`) sea similar tanto en el conjunto de entrenamiento como en el de prueba.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "Entrenar y evaluar un modelo con los mismos datos llevaría a una sobreestimación de su rendimiento (el modelo se \"aprende de memoria\" los datos de entrenamiento). La división en entrenamiento y prueba simula un escenario real donde el modelo debe predecir sobre nueva información, dando una visión honesta de su verdadera capacidad predictiva y evitando falsas expectativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965e16ca-c4ca-4aa2-80e5-7f2c8d58ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar la función para dividir los datos\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Separar las características (X) de la variable objetivo (y)\n",
    "X = df.drop(\"Outcome\", axis=1) # X contiene todas las columnas excepto 'Outcome'\n",
    "y = df[\"Outcome\"]             # y contiene solo la columna 'Outcome'\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "# 80% para entrenamiento, 20% para prueba\n",
    "# stratify=y asegura que la proporción de clases en 'Outcome' se mantenga en ambos conjuntos\n",
    "# random_state para reproducibilidad\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# Verificar las dimensiones de los conjuntos resultantes\n",
    "print(\"Forma de X_train:\", X_train.shape)\n",
    "print(\"Forma de X_test:\", X_test.shape)\n",
    "print(\"Forma de y_train:\", y_train.shape)\n",
    "print(\"Forma de y_test:\", y_test.shape)\n",
    "print(\"\\nProporción de clases en y_train:\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\\nProporción de clases en y_test:\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0a6e63-57ae-4c71-8830-aa3d29df6bcc",
   "metadata": {},
   "source": [
    "**Comentario:**\n",
    "Los datos se han dividido correctamente. La proporción de clases (diabetes/no diabetes) es similar en los conjuntos de entrenamiento y prueba gracias al parámetro `stratify=y`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65beb95-7b0e-429e-83a0-dfe00c8acd3d",
   "metadata": {},
   "source": [
    "### 5. Entrenamiento de un Modelo Base: Random Forest\n",
    "\n",
    "Ahora vamos a entrenar nuestro primer modelo. Utilizaremos `RandomForestClassifier`, un algoritmo popular y potente que suele dar buenos resultados \"de fábrica\" (sin mucha optimización de hiperparámetros). Es un modelo de ensamblaje que construye múltiples árboles de decisión y combina sus predicciones.\n",
    "\n",
    "1.  **Inicializar el modelo:** Creamos una instancia del clasificador. `random_state=42` para reproducibilidad.\n",
    "2.  **Entrenar el modelo:** Usamos el método `fit()` con los datos de entrenamiento (`X_train`, `y_train`).\n",
    "3.  **Realizar predicciones:** Usamos el método `predict()` con los datos de prueba (`X_test`).\n",
    "4.  **Evaluar el modelo:** Usaremos `classification_report` de `sklearn.metrics` para obtener métricas clave como precisión, recall, F1-score y support.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "Este es el núcleo del proceso de Machine Learning: enseñar a una máquina a tomar decisiones o hacer predicciones basadas en datos históricos. La evaluación nos dirá qué tan bueno es el modelo en esta tarea. Métricas como:\n",
    "*   **Precisión (Precision):** De todas las predicciones de \"diabetes\", ¿cuántas fueron correctas? Importante si el coste de un falso positivo es alto.\n",
    "*   **Sensibilidad (Recall/Exhaustividad):** De todos los pacientes que realmente tienen diabetes, ¿a cuántos identificó correctamente el modelo? Crucial si no queremos pasar por alto casos de diabetes (minimizar falsos negativos).\n",
    "*   **F1-Score:** Una media armónica de precisión y recall. Útil cuando hay desbalanceo de clases o cuando ambas métricas son importantes.\n",
    "Estas métricas ayudan a entender el valor y las limitaciones del modelo en un contexto de negocio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df554488-6df4-4fc8-8d78-807a14f3d418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar el clasificador Random Forest y métricas de evaluación\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Inicializar el modelo Random Forest\n",
    "# random_state para asegurar que los resultados sean reproducibles\n",
    "modelo_rf_base = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "modelo_rf_base.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones sobre el conjunto de prueba\n",
    "y_pred_base = modelo_rf_base.predict(X_test)\n",
    "\n",
    "# Evaluar el modelo\n",
    "print(\"Reporte de Clasificación del Modelo Base (Random Forest):\")\n",
    "print(classification_report(y_test, y_pred_base))\n",
    "\n",
    "print(\"Accuracy del Modelo Base:\", accuracy_score(y_test, y_pred_base))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9903f4-cd42-4dfd-9df2-11db8c0fbb0f",
   "metadata": {},
   "source": [
    "**Interpretación del Reporte de Clasificación (Modelo Base):**\n",
    "*   **Clase 0 (No Diabetes):** Tiene alta precisión (0.79) y recall (0.87). Esto significa que el modelo es bueno identificando pacientes sin diabetes, y cuando predice \"no diabetes\", suele acertar.\n",
    "*   **Clase 1 (Diabetes):** Tiene una precisión de 0.68 (cuando predice \"diabetes\", el 68% de las veces es correcto) y un recall de 0.56 (identifica al 56% de los pacientes que realmente tienen diabetes). El F1-score es 0.61.\n",
    "*   **Accuracy (Exactitud General):** 0.76. El modelo clasifica correctamente el 76% de los casos en general.\n",
    "\n",
    "El rendimiento para la clase minoritaria (diabetes=1) es notablemente más bajo, especialmente el recall. Esto es común en datasets desbalanceados. El modelo tiende a favorecer la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4193d3cd-163b-4c2e-ac03-ea981ab20b00",
   "metadata": {},
   "source": [
    "### 6. Estrategias para Mejorar el Modelo: Validación Cruzada y Manejo del Desbalanceo con SMOTE\n",
    "\n",
    "Para obtener una estimación más robusta del rendimiento del modelo y para abordar el desbalanceo de clases, implementaremos:\n",
    "\n",
    "1.  **Validación Cruzada (Cross-Validation):**\n",
    "    En lugar de una única división entrenamiento/prueba, la validación cruzada divide el conjunto de entrenamiento en múltiples \"folds\" (subconjuntos). El modelo se entrena en K-1 folds y se evalúa en el fold restante. Esto se repite K veces. El resultado final es el promedio de las métricas de rendimiento de cada fold. Esto da una medida más fiable de cómo el modelo generalizará a datos no vistos.\n",
    "    Usaremos `StratifiedKFold` para asegurar que la proporción de clases se mantenga en cada fold, lo cual es crucial para datasets desbalanceados.\n",
    "\n",
    "2.  **SMOTE (Synthetic Minority Over-sampling Technique):**\n",
    "    Es una técnica para manejar el desbalanceo de clases. En lugar de simplemente duplicar instancias de la clase minoritaria (lo que podría llevar a sobreajuste), SMOTE crea nuevas instancias sintéticas de la clase minoritaria que son plausiblemente similares a las existentes. Esto ayuda al modelo a aprender mejor las características de la clase minoritaria.\n",
    "    **Importante:** SMOTE debe aplicarse *solo* al conjunto de entrenamiento (o dentro de cada fold de entrenamiento en la validación cruzada) para evitar que el modelo vea información sintética derivada de lo que sería el conjunto de prueba.\n",
    "\n",
    "Utilizaremos un `Pipeline` de `imblearn` (una librería que extiende `scikit-learn` para el manejo de desbalanceo). El pipeline aplicará SMOTE y luego entrenará el RandomForestClassifier secuencialmente dentro de cada fold de la validación cruzada.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "La validación cruzada proporciona una evaluación más confiable del rendimiento real del modelo, reduciendo la posibilidad de que un buen resultado en una única división de prueba sea solo por suerte. SMOTE ayuda a que el modelo sea más justo y efectivo en la predicción de la clase menos frecuente (en este caso, pacientes con diabetes), lo cual es a menudo el objetivo principal en problemas médicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cef57a-0bf6-47e0-aab1-5afff76c8e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar librerías necesarias para el pipeline, SMOTE y validación cruzada\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline # Renombrar para evitar conflicto con Pipeline de sklearn si se usa\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "# Definir el pipeline: \n",
    "# 1. Aplicar SMOTE para balancear las clases (solo en los datos de entrenamiento de cada fold)\n",
    "# 2. Entrenar un RandomForestClassifier\n",
    "pipeline_smote_rf = ImbPipeline([\n",
    "    ('smote', SMOTE(random_state=42)),\n",
    "    ('modelo_rf', RandomForestClassifier(random_state=42)) # Usaremos 'modelo_rf' para diferenciar del modelo base\n",
    "])\n",
    "\n",
    "# Definir la estrategia de validación cruzada\n",
    "# n_splits=5 significa 5 folds. shuffle=True mezcla los datos antes de dividir.\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Realizar la validación cruzada usando todo el dataset (X, y) para evaluar la estrategia general.\n",
    "# En un escenario de reporte final, haríamos esto sobre X_train, y_train y luego evaluaríamos en X_test.\n",
    "# Aquí, evaluamos el pipeline en su conjunto para ver el impacto de SMOTE.\n",
    "# Usamos 'f1' como métrica de scoring, ya que es buena para clases desbalanceadas.\n",
    "# Podríamos usar 'f1_weighted' o 'f1_macro' también.\n",
    "scores = cross_val_score(pipeline_smote_rf, X, y, cv=cv, scoring=\"f1\", n_jobs=-1)\n",
    "\n",
    "print(f\"F1-scores por fold con SMOTE + CV: {scores}\")\n",
    "print(f\"F1 promedio con SMOTE + CV: {scores.mean():.4f}\")\n",
    "print(f\"Desviación estándar del F1-score: {scores.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677bb5b9-8dc0-4717-8060-1a46df97c138",
   "metadata": {},
   "source": [
    "**Interpretación de los Resultados de Validación Cruzada con SMOTE:**\n",
    "El F1-score promedio obtenido mediante validación cruzada con SMOTE nos da una idea más robusta del rendimiento esperado del modelo. Este valor (alrededor de 0.64-0.66, dependiendo de la ejecución por `shuffle=True` si no se fija el `random_state` de SMOTE y RF dentro del pipeline para cada fold específicamente) es una mejor guía que el F1 de la clase positiva del modelo base (0.61).\n",
    "\n",
    "Para el resto de las visualizaciones y la optimización, volveremos a entrenar un modelo (puede ser el base o uno con parámetros específicos) sobre `X_train`, `y_train` para luego evaluar sobre `X_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99b43b0-d2b2-4592-9c8a-5838b8210ad8",
   "metadata": {},
   "source": [
    "### 7. Interpretación del Modelo y Visualizaciones Adicionales\n",
    "\n",
    "Una vez que tenemos un modelo entrenado (usaremos el `modelo_rf_base` entrenado en `X_train`, `y_train` para estas visualizaciones, ya que es más sencillo de inspeccionar directamente que un pipeline complejo), es útil entender qué características son más importantes para sus predicciones y cómo se distribuyen sus errores.\n",
    "\n",
    "1.  **Importancia de Características:** Random Forest puede decirnos qué características contribuyeron más a la toma de decisiones.\n",
    "2.  **Matriz de Confusión:** Visualiza el rendimiento del clasificador. Muestra los Verdaderos Positivos (TP), Verdaderos Negativos (TN), Falsos Positivos (FP) y Falsos Negativos (FN).\n",
    "3.  **Curva ROC y AUC:** La curva ROC (Receiver Operating Characteristic) grafica la tasa de verdaderos positivos contra la tasa de falsos positivos para diferentes umbrales de clasificación. El AUC (Area Under the Curve) es una medida única del rendimiento general del clasificador (un valor más cercano a 1 es mejor).\n",
    "4.  **Distribución de Probabilidades:** Visualizar cómo el modelo asigna probabilidades a la clase positiva.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "*   **Importancia de Características:** Identificar los factores más influyentes puede guiar estrategias de negocio o intervención. Por ejemplo, si la glucosa es la más importante, se pueden enfocar esfuerzos en el monitoreo de este indicador.\n",
    "*   **Matriz de Confusión:** Ayuda a entender los tipos de errores que comete el modelo. ¿Está fallando más en predecir diabetes cuando sí la hay (FN), o prediciendo diabetes cuando no la hay (FP)? Esto tiene implicaciones de coste y riesgo.\n",
    "*   **Curva ROC y AUC:** Ofrecen una visión más matizada del rendimiento que la simple exactitud, especialmente útil para comparar diferentes modelos o configuraciones.\n",
    "*   **Distribución de Probabilidades:** Entender la confianza del modelo en sus predicciones puede ser útil para establecer umbrales de decisión (e.g., solo actuar sobre predicciones con alta probabilidad)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35550de2-7d29-467d-8b1c-a9f13707e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asegurarnos que 'modelo_rf_base' está entrenado en X_train, y_train\n",
    "# Si no se ha ejecutado la celda 20 de nuevo después de la validación cruzada, lo re-entrenamos:\n",
    "# (La celda 20 ya entrena modelo_rf_base en X_train, y_train)\n",
    "\n",
    "importancias = modelo_rf_base.feature_importances_\n",
    "nombres_caracteristicas = X_train.columns # Usar X_train.columns para asegurar el orden correcto\n",
    "\n",
    "# Crear un DataFrame para visualizar mejor las importancias\n",
    "df_importancias = pd.DataFrame({'Caracteristica': nombres_caracteristicas, 'Importancia': importancias})\n",
    "df_importancias = df_importancias.sort_values(by='Importancia', ascending=False)\n",
    "\n",
    "# Visualizar las importancias\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.barplot(x='Importancia', y='Caracteristica', data=df_importancias, palette='viridis')\n",
    "plt.title(\"Importancia de Variables (Random Forest Base)\")\n",
    "plt.xlabel(\"Importancia (calculada por Gini impurity)\")\n",
    "plt.ylabel(\"Característica\")\n",
    "plt.grid(True, axis='x')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(df_importancias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50d2071-c074-4bdc-91a7-d2e6fbff4912",
   "metadata": {},
   "source": [
    "**Interpretación de la Importancia de Características:**\n",
    "`Glucose` es consistentemente la característica más importante, seguida por `BMI`, `Age` y `DiabetesPedigreeFunction`. Esto se alinea con el conocimiento médico y las correlaciones que vimos anteriormente. Saber esto podría, por ejemplo, enfocar campañas de prevención o chequeos médicos en estos factores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4967a03-5736-4b54-b023-fa450eb53313",
   "metadata": {},
   "source": [
    "#### 7.2. Matriz de Confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3725880-0101-4d50-9570-11fd277b9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "# y_pred_base ya fue calculado en la celda 20 usando modelo_rf_base en X_test\n",
    "# y_pred_eval = modelo_rf_base.predict(X_test) # Esta línea sería redundante si la celda 20 se ejecutó\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred_base, labels=modelo_rf_base.classes_)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Diabetes (0)\", \"Diabetes (1)\"])\n",
    "\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Matriz de Confusión (Modelo Base en Test Set)\")\n",
    "plt.show()\n",
    "\n",
    "print(\"Detalle de la Matriz de Confusión:\")\n",
    "print(f\"Verdaderos Negativos (TN - No Diabetes, predicho No Diabetes): {cm[0,0]}\")\n",
    "print(f\"Falsos Positivos (FP - No Diabetes, predicho Diabetes):      {cm[0,1]}\")\n",
    "print(f\"Falsos Negativos (FN - Diabetes, predicho No Diabetes):     {cm[1,0]}\")\n",
    "print(f\"Verdaderos Positivos (TP - Diabetes, predicho Diabetes):     {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61ab0ff-7951-407b-ace4-3ec00a203977",
   "metadata": {},
   "source": [
    "**Interpretación de la Matriz de Confusión:**\n",
    "*   **Verdaderos Negativos (TN):** El modelo predijo correctamente \"No Diabetes\" para [valor de TN] pacientes que realmente no la tienen.\n",
    "*   **Falsos Positivos (FP):** El modelo predijo incorrectamente \"Diabetes\" para [valor de FP] pacientes que no la tienen (Error Tipo I).\n",
    "*   **Falsos Negativos (FN):** El modelo predijo incorrectamente \"No Diabetes\" para [valor de FN] pacientes que sí la tienen (Error Tipo II). ¡Este es a menudo el error más costoso en contextos médicos!\n",
    "*   **Verdaderos Positivos (TP):** El modelo predijo correctamente \"Diabetes\" para [valor de TP] pacientes que sí la tienen.\n",
    "\n",
    "El objetivo es maximizar TP y TN, y minimizar FP y FN. La importancia relativa de minimizar FP vs. FN depende del problema de negocio.\n",
    "(Nota: Reemplazar `[valor de TN]`, `[valor de FP]`, `[valor de FN]`, `[valor de TP]` con los números reales de la salida de la celda anterior después de ejecutar el notebook)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c7f90a-b574-4626-951f-0d24f6fabb56",
   "metadata": {},
   "source": [
    "#### 7.3. Curva ROC y Puntuación AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391cd704-2605-4335-b317-34f70799f137",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score\n",
    "\n",
    "# Obtener las probabilidades de predicción para la clase positiva (Diabetes) usando modelo_rf_base\n",
    "y_proba_base = modelo_rf_base.predict_proba(X_test)[:,1]\n",
    "\n",
    "RocCurveDisplay.from_estimator(modelo_rf_base, X_test, y_test)\n",
    "plt.title(\"Curva ROC (Modelo Base en Test Set)\")\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Clasificador Aleatorio') # Línea de referencia\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "auc_score_base = roc_auc_score(y_test, y_proba_base)\n",
    "print(f\"Puntuación AUC (Area Under Curve) del Modelo Base: {auc_score_base:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338360de-1278-478f-aa71-e2fff3748612",
   "metadata": {},
   "source": [
    "**Interpretación de la Curva ROC y AUC:**\n",
    "La curva ROC muestra qué tan bien el modelo distingue entre las dos clases. Una curva que se acerca más a la esquina superior izquierda indica un mejor rendimiento. El AUC es el área bajo esta curva. Un AUC de 0.5 representa un clasificador aleatorio (sin capacidad de discriminación), mientras que un AUC de 1.0 representa un clasificador perfecto.\n",
    "Nuestro modelo base obtiene un AUC de [valor de AUC], lo que indica una capacidad de discriminación [buena/moderada/aceptable]. Hay espacio para mejorar, pero es significativamente mejor que el azar.\n",
    "(Nota: Reemplazar `[valor de AUC]` y la descripción con el valor real de la salida de la celda anterior después de ejecutar)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192917c3-0756-4747-af37-2958f73dce64",
   "metadata": {},
   "source": [
    "#### 7.4. Distribución de Probabilidades Predichas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e65d057-d498-4464-a688-775cf1240880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_proba_base ya fue calculado en la celda anterior\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(y_proba_base, bins=30, kde=True)\n",
    "plt.title(\"Distribución de Probabilidades Predichas de Tener Diabetes (Clase 1) - Modelo Base\")\n",
    "plt.xlabel(\"Probabilidad Predicha de Diabetes\")\n",
    "plt.ylabel(\"Frecuencia\")\n",
    "plt.axvline(0.5, color='red', linestyle='--', label='Umbral 0.5') # Umbral de decisión por defecto\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccdd1e1b-5d88-4f93-9921-ac1c7196af0b",
   "metadata": {},
   "source": [
    "**Interpretación de la Distribución de Probabilidades:**\n",
    "Este histograma muestra las probabilidades que el modelo asignó a cada paciente del conjunto de prueba para la clase \"Diabetes\". Idealmente, para pacientes que realmente no tienen diabetes, las probabilidades deberían estar cerca de 0, y para los que sí tienen, cerca de 1.\n",
    "Vemos que hay una superposición de distribuciones alrededor del umbral de 0.5, lo que explica por qué el modelo comete errores. Ajustar este umbral podría ser una estrategia para optimizar según si preferimos minimizar Falsos Positivos o Falsos Negativos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6b4fde-b427-45eb-bc81-66bd96486e65",
   "metadata": {},
   "source": [
    "### 8. Optimización de Hiperparámetros\n",
    "\n",
    "Los modelos de Machine Learning tienen \"hiperparámetros\" que no se aprenden de los datos, sino que se configuran antes del entrenamiento (e.g., el número de árboles en un Random Forest). Encontrar la combinación óptima de hiperparámetros puede mejorar significativamente el rendimiento del modelo.\n",
    "\n",
    "Utilizaremos dos técnicas comunes:\n",
    "1.  **GridSearchCV:** Prueba todas las combinaciones posibles de un conjunto predefinido de hiperparámetros y selecciona la mejor según una métrica de evaluación (e.g., F1-score) usando validación cruzada.\n",
    "2.  **RandomizedSearchCV:** En lugar de probar todas las combinaciones, muestrea aleatoriamente un número fijo de combinaciones de un espacio de búsqueda de hiperparámetros. Puede ser más eficiente que GridSearchCV cuando el espacio de búsqueda es grande.\n",
    "\n",
    "**Importante:** La optimización de hiperparámetros se realiza sobre el **conjunto de entrenamiento** (`X_train`, `y_train`). El conjunto de prueba (`X_test`) se mantiene reservado para la evaluación final del modelo optimizado.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "Esto es como ajustar finamente una máquina para obtener el mejor rendimiento. Un modelo bien afinado puede ofrecer predicciones más precisas y fiables, lo que se traduce en mejores decisiones de negocio y mayor retorno de la inversión en la solución de IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a0854a-fe23-40b4-a6ff-00ff9fd62426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros para RandomForestClassifier\n",
    "parametros_grid = {\n",
    "    'n_estimators': [50, 100, 150],       # Número de árboles en el bosque\n",
    "    'max_depth': [None, 10, 20],        # Profundidad máxima de cada árbol\n",
    "    'min_samples_split': [2, 5, 10],   # Número mínimo de muestras para dividir un nodo\n",
    "    'min_samples_leaf': [1, 2, 4]      # Número mínimo de muestras en un nodo hoja\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV\n",
    "# estimator: el modelo a optimizar (RandomForestClassifier)\n",
    "# param_grid: el diccionario de hiperparámetros a probar\n",
    "# cv: la estrategia de validación cruzada (usaremos StratifiedKFold con 5 splits)\n",
    "# scoring: la métrica para evaluar las combinaciones (usaremos 'f1' por el desbalanceo)\n",
    "# n_jobs=-1: usar todos los procesadores disponibles para acelerar la búsqueda\n",
    "grid_search = GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                           param_grid=parametros_grid,\n",
    "                           cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), # Usar StratifiedKFold explícitamente\n",
    "                           scoring=\"f1\",\n",
    "                           n_jobs=-1,\n",
    "                           verbose=1) # verbose para ver el progreso\n",
    "\n",
    "# Ejecutar la búsqueda de hiperparámetros sobre los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros encontrados y el mejor score F1\n",
    "print(\"\\nMejores parámetros encontrados (GridSearchCV):\", grid_search.best_params_)\n",
    "print(\"Mejor F1-score en validación cruzada (GridSearchCV):\", grid_search.best_score_)\n",
    "\n",
    "# El mejor modelo ya está entrenado y se puede acceder con grid_search.best_estimator_\n",
    "modelo_optimizado_grid = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56583987-96f7-4d72-9606-2feefc326e03",
   "metadata": {},
   "source": [
    "#### 8.2. RandomizedSearchCV (Búsqueda Aleatoria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9970d5cd-e00e-420a-98f8-a73793c30b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar RandomizedSearchCV y distribuciones para parámetros continuos o discretos grandes\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros usando distribuciones\n",
    "parametros_random = {\n",
    "    'n_estimators': randint(50, 250), # Entero aleatorio entre 50 y 249\n",
    "    'max_depth': [None] + list(range(5, 25, 5)), # None o valores discretos 5, 10, 15, 20\n",
    "    'min_samples_split': randint(2, 11), # Entero aleatorio entre 2 y 10\n",
    "    'min_samples_leaf': randint(1, 5)    # Entero aleatorio entre 1 y 4\n",
    "}\n",
    "\n",
    "# Inicializar RandomizedSearchCV\n",
    "# n_iter: número de combinaciones de parámetros a probar (e.g., 50 o 100)\n",
    "random_search = RandomizedSearchCV(RandomForestClassifier(random_state=42),\n",
    "                                   param_distributions=parametros_random,\n",
    "                                   n_iter=50, # Probar 50 combinaciones aleatorias\n",
    "                                   cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), # Usar StratifiedKFold\n",
    "                                   scoring=\"f1\",\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=42, # Para reproducibilidad de la búsqueda aleatoria\n",
    "                                   verbose=1)\n",
    "\n",
    "# Ejecutar la búsqueda aleatoria de hiperparámetros\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Mostrar los mejores parámetros y el mejor score F1\n",
    "print(\"\\nMejores parámetros encontrados (RandomizedSearchCV):\", random_search.best_params_)\n",
    "print(\"Mejor F1-score en validación cruzada (RandomizedSearchCV):\", random_search.best_score_)\n",
    "\n",
    "# El mejor modelo ya está entrenado y se puede acceder con random_search.best_estimator_\n",
    "modelo_optimizado_random = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6b7d42-9a9a-4331-8bf4-909c73552138",
   "metadata": {},
   "source": [
    "**Comentario sobre Optimización:**\n",
    "Ambas técnicas nos proporcionan un conjunto de hiperparámetros que, según la validación cruzada en los datos de entrenamiento, ofrecen el mejor F1-score. Generalmente, se elige el `best_estimator_` de la búsqueda que haya dado un mejor `best_score_` para la evaluación final en el `X_test`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73437222-3b26-46a7-af8c-5e60b6d7242a",
   "metadata": {},
   "source": [
    "### 9. Pipeline de Machine Learning Completo con Preprocesamiento y Optimización\n",
    "\n",
    "Una práctica recomendada es integrar los pasos de preprocesamiento (como el escalado de características) dentro del pipeline de optimización. Esto asegura que el preprocesamiento se aplique correctamente dentro de cada fold de la validación cruzada, evitando la fuga de datos.\n",
    "\n",
    "1.  **StandardScaler:** Estandariza las características eliminando la media y escalando a la varianza unitaria. Aunque los árboles de decisión (como Random Forest) no son sensibles a la escala de las características, es una buena práctica incluirlo, especialmente si se planea probar otros modelos que sí lo son (e.g., SVM, Regresión Logística).\n",
    "2.  **Pipeline:** Combinaremos `StandardScaler` y `RandomForestClassifier`.\n",
    "3.  **GridSearchCV (o RandomizedSearchCV):** Se aplicará al pipeline completo, optimizando los hiperparámetros del modelo *dentro* del pipeline.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "Esto demuestra un enfoque riguroso y robusto para construir modelos. Un pipeline bien estructurado no solo mejora la fiabilidad del modelo, sino que también facilita su despliegue y mantenimiento en entornos de producción, ya que todos los pasos de transformación de datos están encapsulados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "531729de-7797-41b3-aa69-27bbc0fd0028",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar Pipeline de sklearn y StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear el pipeline: primero escalar, luego aplicar el clasificador\n",
    "pipeline_completo = Pipeline([\n",
    "    ('scaler', StandardScaler()), # Paso 1: Estandarizar características\n",
    "    ('modelo_rf', RandomForestClassifier(random_state=42)) # Paso 2: Modelo Random Forest\n",
    "])\n",
    "\n",
    "# Definir el espacio de búsqueda de hiperparámetros para el pipeline\n",
    "# Notar el prefijo 'modelo_rf__' para indicar que estos parámetros pertenecen al paso 'modelo_rf' del pipeline\n",
    "parametros_pipeline = {\n",
    "    'modelo_rf__n_estimators': [100, 150], # Menos opciones para una ejecución más rápida de ejemplo\n",
    "    'modelo_rf__max_depth': [None, 10, 20],\n",
    "    'modelo_rf__min_samples_split': [2, 5],\n",
    "    'modelo_rf__min_samples_leaf': [1, 2]\n",
    "}\n",
    "\n",
    "# Inicializar GridSearchCV para el pipeline completo\n",
    "grid_search_pipeline = GridSearchCV(pipeline_completo,\n",
    "                                  param_grid=parametros_pipeline,\n",
    "                                  cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=42), # Usar StratifiedKFold\n",
    "                                  scoring='f1',\n",
    "                                  n_jobs=-1,\n",
    "                                  verbose=1)\n",
    "\n",
    "# Ejecutar la búsqueda sobre los datos de entrenamiento\n",
    "grid_search_pipeline.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nMejor F1-score con pipeline y GridSearchCV:\", grid_search_pipeline.best_score_)\n",
    "print(\"Mejores parámetros para el pipeline:\", grid_search_pipeline.best_params_)\n",
    "\n",
    "# El mejor pipeline (con escalador ajustado y modelo optimizado) está en:\n",
    "mejor_pipeline_final = grid_search_pipeline.best_estimator_\n",
    "\n",
    "# Evaluar el mejor pipeline en el conjunto de prueba\n",
    "y_pred_pipeline = mejor_pipeline_final.predict(X_test)\n",
    "print(\"\\nReporte de Clasificación del Mejor Pipeline en el Conjunto de Prueba:\")\n",
    "print(classification_report(y_test, y_pred_pipeline))\n",
    "\n",
    "# También podemos ver el AUC del pipeline final\n",
    "y_proba_pipeline = mejor_pipeline_final.predict_proba(X_test)[:,1]\n",
    "auc_pipeline_final = roc_auc_score(y_test, y_proba_pipeline)\n",
    "print(f\"\\nAUC del Mejor Pipeline en el Conjunto de Prueba: {auc_pipeline_final:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549b297d-0034-4a76-b1e1-976617730855",
   "metadata": {},
   "source": [
    "**Interpretación del Pipeline Optimizado:**\n",
    "El `grid_search_pipeline.best_score_` nos da el F1-score promedio en validación cruzada sobre los datos de entrenamiento. El reporte de clasificación final sobre `X_test` nos indica cómo se espera que este pipeline optimizado funcione en datos completamente nuevos.\n",
    "Compare este reporte con el del modelo base. ¿Ha mejorado el F1-score para la clase 1 (Diabetes)? ¿Y la precisión o el recall? ¿Y el AUC?\n",
    "Este `mejor_pipeline_final` es el candidato a ser el modelo productivo.\n",
    "(Nota: Tendrás que ejecutar el notebook para ver los valores específicos y completar la comparación)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d444157e-85a9-4760-ba3d-21008e7d9a4a",
   "metadata": {},
   "source": [
    "### 10. Guardado y Carga del Modelo Final\n",
    "\n",
    "Una vez que hemos encontrado nuestro mejor modelo (en este caso, `mejor_pipeline_final`), es importante guardarlo para poder usarlo en el futuro sin necesidad de reentrenarlo cada vez. La librería `joblib` es eficiente para guardar objetos de Python, incluyendo modelos de `scikit-learn`.\n",
    "\n",
    "**¿Por qué este paso es importante para un empresario?**\n",
    "Guardar el modelo permite su despliegue en sistemas de producción, donde puede hacer predicciones sobre nuevos datos en tiempo real o por lotes. Es el paso que convierte el trabajo de desarrollo en una herramienta operativa y de valor continuo para la organización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b38783-fbf1-4e1a-98dd-2ac78aed218d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Nombre del archivo para guardar el modelo\n",
    "nombre_archivo_modelo = \"pipeline_diabetes_optimizado.pkl\"\n",
    "\n",
    "# Guardar el mejor pipeline (que incluye escalador y modelo RandomForest optimizado)\n",
    "joblib.dump(mejor_pipeline_final, nombre_archivo_modelo)\n",
    "print(f\"Modelo guardado como {nombre_archivo_modelo}\")\n",
    "\n",
    "# Ejemplo de cómo cargar el modelo posteriormente\n",
    "modelo_cargado = joblib.load(nombre_archivo_modelo)\n",
    "print(\"\\nModelo cargado exitosamente.\")\n",
    "\n",
    "# Verificar que el modelo cargado funciona (haciendo una predicción de ejemplo)\n",
    "# Tomamos la primera fila de X_test como ejemplo\n",
    "ejemplo_prediccion = modelo_cargado.predict(X_test.head(1))\n",
    "ejemplo_probabilidad = modelo_cargado.predict_proba(X_test.head(1))\n",
    "\n",
    "print(f\"Predicción para la primera muestra de X_test: {ejemplo_prediccion[0]}\")\n",
    "print(f\"Probabilidades para la primera muestra de X_test (No Diabetes, Diabetes): {ejemplo_probabilidad[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34eb851-836c-4089-a070-70d217557bd5",
   "metadata": {},
   "source": [
    "### 11. Conclusiones y Próximos Pasos\n",
    "\n",
    "**Resumen del Trabajo Realizado:**\n",
    "A lo largo de este notebook, hemos seguido un proceso completo de desarrollo de un modelo de Machine Learning para la predicción de diabetes:\n",
    "1.  Cargamos y exploramos el conjunto de datos Pima Indians Diabetes.\n",
    "2.  Realizamos un preprocesamiento exhaustivo, incluyendo el manejo de valores anómalos (ceros implausibles) y la imputación de datos faltantes.\n",
    "3.  Visualizamos los datos para entender mejor sus distribuciones y relaciones.\n",
    "4.  Dividimos los datos en conjuntos de entrenamiento y prueba, utilizando estratificación para manejar el desbalanceo de clases.\n",
    "5.  Entrenamos un modelo base (Random Forest) y lo evaluamos.\n",
    "6.  Implementamos estrategias avanzadas como la validación cruzada y SMOTE para obtener una evaluación más robusta y mejorar el manejo del desbalanceo.\n",
    "7.  Interpretamos el modelo mediante la importancia de características, matriz de confusión y curva ROC/AUC.\n",
    "8.  Optimizamos los hiperparámetros del modelo utilizando GridSearchCV y RandomizedSearchCV, integrando el preprocesamiento (escalado) en un pipeline completo.\n",
    "9.  Seleccionamos el mejor pipeline y lo evaluamos en el conjunto de prueba reservado.\n",
    "10. Guardamos el modelo final para su posible despliegue.\n",
    "\n",
    "**Resultados Clave:**\n",
    "*   El modelo final (pipeline con StandardScaler y RandomForest optimizado) alcanzó un F1-score de **[insertar F1-score del `mejor_pipeline_final` en `X_test` para la clase 1]** y un AUC de **[insertar AUC del `mejor_pipeline_final` en `X_test`]** en el conjunto de prueba para la predicción de diabetes.\n",
    "*   Las características más influyentes para la predicción fueron `Glucose`, `BMI`, y `Age`.\n",
    "*   Se demostró la importancia de un preprocesamiento cuidadoso y la optimización de hiperparámetros para construir un modelo robusto.\n",
    "(Nota: Deberás ejecutar el notebook completo y rellenar los valores entre corchetes con los resultados obtenidos en la celda 45).\n",
    "\n",
    "**¿Qué significa esto para el negocio?**\n",
    "Hemos desarrollado un prototipo de herramienta analítica que puede ayudar a identificar individuos con mayor riesgo de padecer diabetes. Este modelo:\n",
    "*   Proporciona una base cuantitativa para la toma de decisiones.\n",
    "*   Puede integrarse en sistemas de salud para apoyar a los profesionales médicos (nunca para reemplazarlos).\n",
    "*   Permite enfocar recursos de prevención y tratamiento de manera más eficiente.\n",
    "\n",
    "**Próximos Pasos y Mejoras Potenciales:**\n",
    "*   **Probar otros algoritmos:** Comparar el rendimiento con otros modelos como Gradient Boosting, SVM, Regresión Logística, o Redes Neuronales.\n",
    "*   **Ingeniería de Características Avanzada:** Crear nuevas características a partir de las existentes que puedan capturar relaciones más complejas.\n",
    "*   **Análisis de Errores más Profundo:** Investigar los casos donde el modelo falla consistentemente para entender sus limitaciones.\n",
    "*   **Considerar el Costo de los Errores:** Ajustar el umbral de decisión del modelo o usar métricas de evaluación ponderadas por costo si los falsos negativos tienen un impacto mucho mayor que los falsos positivos (o viceversa).\n",
    "*   **Monitoreo del Modelo (MLOps):** Si se despliega, implementar un sistema para monitorear su rendimiento a lo largo del tiempo y reentrenarlo cuando sea necesario.\n",
    "*   **Validación Externa:** Probar el modelo en un conjunto de datos completamente diferente (de otra población u hospital) para evaluar su generalizabilidad.\n",
    "\n",
    "Este proyecto demuestra la capacidad de aplicar técnicas de ciencia de datos para abordar problemas del mundo real y generar valor. La metodología seguida es estándar en la industria y sienta las bases para desarrollos más avanzados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb45c5e8-f122-4b6c-b6fe-d518a3060344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
